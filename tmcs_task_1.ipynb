{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1. Итерационный метод нахождения СЗ и СВ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Грамотно протестировать  \n",
    "Спектральное разложение  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Источник](http://mathhelpplanet.com/static.php?p=metody-resheniya-zadach-o-sobstvennykh-znacheniyakh-i-vektorakh-matritsy)  \n",
    "Если не работает, то имеет смысл воспользоваться вебархивом.  \n",
    "\n",
    "\n",
    "Полезные ссылки:  \n",
    "http://mlwiki.org/index.php/Power_Iteration - здесь дучше объеяснено\n",
    "\n",
    "https://slemeshevsky.github.io/num-mmf/eigen/html/._eigen-FlatUI001.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Постановка задачи\n",
    "\n",
    "Пусть ${A}$ — действительная числовая квадратная матрица размера ${(n\\times n)}$. Ненулевой вектор ${X= \\bigl(x_1,\\ldots,x_n\\bigr)^T}$ размера ${(n\\times1)}$, удовлетворяющий условию\n",
    "\n",
    "\n",
    "${A\\cdot X= \\lambda\\cdot X,\\qquad \\mathsf{(2.1)}}$\n",
    "\n",
    "называется собственным вектором матрицы ${A}$. Число ${\\lambda}$ в равенстве (2.1) называется собственным значением. Говорят, что собственный вектор ${X}$ соответствует (принадлежит) собственному значению ${\\lambda}$.\n",
    "\n",
    "\n",
    "Равенство (2.1) равносильно однородной относительно ${X}$ системе:\n",
    "\n",
    "\n",
    "${(A-\\lambda E)\\cdot X=0\\quad (X\\ne 0).\\qquad \\mathsf{(2.2)}}$\n",
    "\n",
    "Система (2.2) имеет ненулевое решение для вектора ${X}$ (при известном ${\\lambda}$) при условии ${|A-\\lambda E|=0}$. Это равенство есть характеристическое уравнение:\n",
    "\n",
    "\n",
    "${|A-\\lambda E|= P_n(\\lambda)=0,}$(2.3)\n",
    "\n",
    "где ${P_n(\\lambda)}$ — характеристический многочлен n-й степени. Корни ${\\lambda_1, \\lambda_2,\\ldots,\\lambda_n}$ характеристического уравнения (2.3) являются собственными (характеристическими) значениями матрицы ${A}$, а соответствующие каждому собственному значению ${\\lambda_i,~ i=1,\\ldots,n}$, ненулевые векторы ${X^i}$, удовлетворяющие системе\n",
    "\n",
    "\n",
    "${AX^i=\\lambda_iX^i\\quad \\text{or}\\quad (A-\\lambda_i E)X^i=0,~~ i=1,2,\\ldots,n,}$(2.4)\n",
    "\n",
    "являются собственными векторами.\n",
    "\n",
    "\n",
    "Требуется найти собственные значения и собственные векторы заданной матрицы. Поставленная задача часто именуется второй задачей линейной алгебры.\n",
    "\n",
    "\n",
    "Проблема собственных значений (частот) возникает при анализе поведения мостов, зданий, летательных аппаратов и других конструкций, характеризующихся малыми смещениями от положения равновесия, а также при анализе устойчивости численных схем. Характеристическое уравнение вместе с его собственными значениями и собственными векторами является основным в теории механических или электрических колебаний на макроскопическом или микроскопическом\n",
    "уровнях.\n",
    "\n",
    "\n",
    "Различают полную и частичную проблему собственных значений, когда необходимо найти весь спектр (все собственные значения) и собственные векторы либо часть спектра, например: ${\\rho(A)= \\max_{i}|\\lambda_i(A)|}$ и ${\\min_{i}|\\lambda_i(A)|}$. Величина ${\\rho(A)}$ называется спектральным радиусом.\n",
    "\n",
    "\n",
    "__Замечания__\n",
    "\n",
    "\n",
    "1. Если для собственного значения ${\\lambda_i}$ — найден собственный вектор ${X^i}$, то вектор ${\\mu X^i}$, где ${\\mu}$ — произвольное число, также является собственным вектором, соответствующим этому же собственному значению ${\\lambda_i}$.\n",
    "\n",
    "\n",
    "2. Попарно различным собственным значениям соответствуют линейно независимые собственные векторы; k-кратному корню характеристического уравнения соответствует не более ${k}$ линейно независимых собственных векторов.\n",
    "\n",
    "\n",
    "3. Симметрическая матрица имеет полный спектр ${\\lambda_i,~ i=\\overline{1,n}}$, действительных собственных значений; k-кратному корню характеристического уравнения симметрической матрицы соответствует ровно ${k}$ линейно независимых собственных векторов.\n",
    "\n",
    "\n",
    "4. Положительно определенная симметрическая матрица имеет полный спектр действительных положительных собственных значений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод итераций для нахождения собственных значений и векторов\n",
    "\n",
    "\n",
    "Для решения частичной проблемы собственных значений и собственных векторов в практических расчетах часто используется метод итераций (степенной метод). На его основе можно определить приближенно собственные значения матрицы ${A}$ и спектральный радиус ${\\rho(A)= \\max_{i}\\bigl|\\lambda_i(A)\\bigr|}$.\n",
    "\n",
    "\n",
    "Пусть матрица ${A}$ имеет ${n}$ линейно независимых собственных векторов ${X^i,~ i=1,\\ldots,n}$, и собственные значения матрицы ${A}$ таковы, что\n",
    "\n",
    "\n",
    "${\\rho(A)= \\bigl|\\lambda_1(A)\\bigr|> \\bigl|\\lambda_2(A)\\bigr|\\geqslant \\ldots\\geqslant \\bigl|\\lambda_n(A)\\bigr|.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритм метода итераций\n",
    "\n",
    "1. Выбрать произвольное начальное (нулевое) приближение собственного вектора ${X^{1(0)}}$ (второй индекс в скобках здесь и ниже указывает номер приближения, а первый индекс без скобок соответствует номеру собственного значения). Положить ${k=0}$.\n",
    "\n",
    "\n",
    "2. Найти ${X^{1(1)}=AX^{1(0)},~ \\lambda_1^{(1)}= \\frac{x_i^{1(1)}}{x_i^{1(0)}}}$, где ${i}$ — любой номер ${1\\leqslant i\\leqslant n}$, и положить ${k=1}$.\n",
    "\n",
    "\n",
    "3. Вычислить ${X^{1(k+1)}=A\\cdot X^{1(k)}}$.\n",
    "\n",
    "\n",
    "4. Найти ${\\lambda_1^{(k+1)}= \\frac{x_i^{1(k+1)}}{x_i^{1(k)}}}$, где ${x_i^{1(k+1)}, x_i^{1(k)}}$ — соответствующие координаты векторов ${X^{1(k+1)}}$ и ${X^{1(k)}}$. При этом может быть использована любая координата с номером ${i,~ 1\\leqslant i\\leqslant n}$.\n",
    "\n",
    "\n",
    "5. Если ${\\Delta= \\bigl|\\lambda_1^{(k+1)}- \\lambda_1^{(k)}\\bigr|\\leqslant \\varepsilon}$, процесс завершить и положить ${\\lambda_1\\cong \\lambda_1^{k+1}}$. Если ${\\Delta>\\varepsilon}$, положить ${k=k+1}$ и перейти к пункту 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Замечания__\n",
    "\n",
    "\n",
    "1. Процесс последовательных приближений\n",
    "\n",
    "\n",
    "${\\begin{aligned}&X^{1(1)}= AX^{1(0)},\\quad X^{1(2)}= AX^{1(1)}= A^{2}X^{1(0)},\\quad \\ldots,\\\\ &X^{1(k)}= AX^{1(k-1)}= AA^{k-1}X^{1(0)}= A^kX^{1(0)},\\quad \\ldots \\end{aligned}}$\n",
    "\n",
    "сходится, т.е. при ${x\\to\\infty}$ вектор ${X^{1(k)}}$ стремится к собственному вектору ${X^1}$. Действительно, разложим ${X^{1(0)}}$ по всем собственным векторам: ${\\textstyle{X^{1(0)}= \\sum\\limits_{i=1}^{n} c_iX^i}}$. Так как, согласно (2.4), ${AX^i= \\lambda_iX^i}$, то\n",
    "\n",
    "\n",
    "${\\begin{aligned}& AX^{1(0)}= X^{1(1)}= \\sum\\limits_{i=1}^{n} c_i \\lambda_iX^i,\\quad AX^{1(1)}= A^2X^{1(0)}= X^{1(2)}= \\sum\\limits_{i=1}^{n} c_i \\lambda_i^2X^i,\\quad \\ldots\\\\ &A^kX^{1(0)}= X^{1(k)}= \\sum\\limits_{i=1}^{n} c_i \\lambda_i^kX^i= \\lambda_1^k\\! \\left[c_1X^1+ c_2{\\left(\\frac{\\lambda_2}{\\lambda_1}\\right)\\!}^k X^2+ \\ldots+ c_n{\\left(\\frac{\\lambda_n}{\\lambda_1}\\right)\\!}^k X^n\\right]\\!. \\end{aligned}}$\n",
    "\n",
    "При большом ${k}$ дроби ${{\\left(\\frac{\\lambda_2}{\\lambda_1}\\right)\\!}^k, \\ldots, {\\left(\\frac{\\lambda_n}{\\lambda_1}\\right)\\!}^k}$ малы и поэтому ${A^kX^{1(0)}= c_1\\lambda_1^kX^1}$, то есть ${X^{1(k)}\\to X^1}$ при ${k\\to\\infty}$. Одновременно ${\\lambda_1= \\lim\\limits_{k\\to\\infty} \\frac{x_{i}^{1(k+1)}}{x_{i}^{1(k)}}}$.\n",
    "\n",
    "\n",
    "2. Вместо применяемой в пункте 4 алгоритма формулы для ${\\lambda_1^{(k+1)}}$ можно взять среднее арифметическое соответствующих отношений для разных координат.\n",
    "\n",
    "\n",
    "3. Метод может использоваться и в случае, если наибольшее по модулю собственное значение матрицы ${A}$ является кратным, т.е.\n",
    "\n",
    "\n",
    "${\\lambda_1= \\lambda_2= \\ldots= \\lambda_s}$ и ${\\bigl|\\lambda_1\\bigr|> \\bigl|\\lambda_k\\bigr|}$ при ${k>s}$.\n",
    "\n",
    "4. При неудачном выборе начального приближения ${X^{1(0)}}$ предел отношения ${\\frac{x_i^{1(k+1)}}{x_i^{1(k)}}}$ может не существовать. В этом случае следует задать другое начальное приближение.\n",
    "\n",
    "\n",
    "5. Рассмотренный итерационный процесс для ${\\lambda_1}$ сходится линейно, с параметром ${c=\\frac{\\lambda_2}{\\lambda_1}}$ и может быть очень медленным. Для его ускорения используется алгоритм Эйткена.\n",
    "\n",
    "\n",
    "6. Если ${A=A^T}$ (матрица ${A}$ симметрическая), то сходимость процесса при определении ${\\rho(A)}$ может быть ускорена.\n",
    "\n",
    "\n",
    "7. Используя ${\\lambda_1}$, можно определить следующее значение ${\\lambda_2}$ по формуле ${\\lambda_2= \\frac{x_i^{1(k+1)}- \\lambda_1 x_i^{1(k)}}{x_i^{1(k)}- \\lambda_1 x_i^{1(k-1)}}~ (i=1,2,\\ldots,n)}$. Эта формула дает грубые значения для ${\\lambda_2}$, так как значение ${\\lambda_1}$ является приближенным. Если модули всех собственных значений различны, то на основе последней формулы можно вычислять и остальные ${\\lambda_j~(j=3,4,\\ldots,n)}$.\n",
    "\n",
    "\n",
    "8. После проведения нескольких итераций рекомендуется \"гасить\" растущие компоненты получающегося собственного вектора. Это осуществляется нормировкой вектора, например, по формуле ${\\frac{X^{1(k)}}{\\|X^{1(k)}\\|_1}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4, 3, 2, 1],\n",
       "       [2, 3, 0, 2, 3],\n",
       "       [1, 4, 1, 4, 0],\n",
       "       [4, 1, 1, 1, 0],\n",
       "       [3, 2, 0, 2, 4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# генератор матрицы\n",
    "#s=5\n",
    "#matrix = np.random.randint(0, 5, size=(s, s))\n",
    "matrix = np.array([[3, 4, 3, 2, 1],\n",
    "                   [2, 3, 0, 2, 3],\n",
    "                   [1, 4, 1, 4, 0],\n",
    "                   [4, 1, 1, 1, 0],\n",
    "                   [3, 2, 0, 2, 4]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# прим 6 http://mathprofi.ru/sobstvennye_znachenija_i_sobstvennye_vektory.html\n",
    "\n",
    "matrix =  np.array([[5, -1, -1],\n",
    "                   [0, 4, -1],\n",
    "                   [0, -1, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10.37099706+0.j        , -0.78530762+2.27184363j,\n",
       "        -0.78530762-2.27184363j,  1.14551153+0.j        ,\n",
       "         2.05410664+0.j        ]),\n",
       " array([[-0.55121291+0.j        , -0.12609085+0.47385821j,\n",
       "         -0.12609085-0.47385821j,  0.08161564+0.j        ,\n",
       "         -0.20034807+0.j        ],\n",
       "        [-0.44054679+0.j        , -0.1507622 -0.16051803j,\n",
       "         -0.1507622 +0.16051803j, -0.64279413+0.j        ,\n",
       "          0.55352898+0.j        ],\n",
       "        [-0.38489809+0.j        , -0.39114215-0.40351584j,\n",
       "         -0.39114215+0.40351584j,  0.40906185+0.j        ,\n",
       "         -0.39159848+0.j        ],\n",
       "        [-0.3233697 +0.j        ,  0.5860434 +0.j        ,\n",
       "          0.5860434 -0.j        ,  0.63727102+0.j        ,\n",
       "         -0.6066386 +0.j        ],\n",
       "        [-0.49936795+0.j        ,  0.00514935-0.22753815j,\n",
       "          0.00514935+0.22753815j, -0.08190634+0.j        ,\n",
       "          0.36346465+0.j        ]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eig(matrix) # [0] - сч, [1] - св"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter initial guess vector: \n",
      "x[0]=1\n",
      "x[1]=2\n",
      "x[2]=3\n",
      "x[3]=4\n",
      "x[4]=5\n",
      "Enter tolerable error: 0.000001\n",
      "Enter maximum number of steps: 100\n",
      "\n",
      "STEP 1\n",
      "----------\n",
      "Eigen Value = 35.0000\n",
      "Eigen Vector: \n",
      "0.943\t\n",
      "0.886\t\n",
      "0.800\t\n",
      "0.371\t\n",
      "1.000\t\n",
      "errror=34.0\n",
      "\n",
      "STEP 2\n",
      "----------\n",
      "Eigen Value = 10.5143\n",
      "Eigen Vector: \n",
      "1.000\t\n",
      "0.788\t\n",
      "0.644\t\n",
      "0.554\t\n",
      "0.889\t\n",
      "errror=24.485714285714288\n",
      "\n",
      "STEP 3\n",
      "----------\n",
      "Eigen Value = 10.0815\n",
      "Eigen Vector: \n",
      "1.000\t\n",
      "0.807\t\n",
      "0.696\t\n",
      "0.594\t\n",
      "0.916\t\n",
      "errror=0.43276397515528053\n",
      "\n",
      "STEP 4\n",
      "----------\n",
      "Eigen Value = 10.4202\n",
      "Eigen Vector: \n",
      "1.000\t\n",
      "0.802\t\n",
      "0.701\t\n",
      "0.585\t\n",
      "0.909\t\n",
      "errror=0.3386938942927493\n",
      "\n",
      "STEP 5\n",
      "----------\n",
      "Eigen Value = 10.3891\n",
      "Eigen Vector: \n",
      "1.000\t\n",
      "0.799\t\n",
      "0.698\t\n",
      "0.586\t\n",
      "0.906\t\n",
      "errror=0.03106950962277466\n",
      "\n",
      "STEP 6\n",
      "----------\n",
      "Eigen Value = 10.3676\n",
      "Eigen Vector: \n",
      "1.000\t\n",
      "0.799\t\n",
      "0.698\t\n",
      "0.587\t\n",
      "0.906\t\n",
      "errror=0.021510415668128502\n",
      "\n",
      "STEP 7\n",
      "----------\n",
      "Eigen Value = 10.3709\n",
      "Eigen Vector: \n",
      "1.000\t\n",
      "0.799\t\n",
      "0.698\t\n",
      "0.587\t\n",
      "0.906\t\n",
      "errror=0.003306379934588932\n",
      "\n",
      "STEP 8\n",
      "----------\n",
      "Eigen Value = 10.3713\n",
      "Eigen Vector: \n",
      "1.000\t\n",
      "0.799\t\n",
      "0.698\t\n",
      "0.587\t\n",
      "0.906\t\n",
      "errror=0.00032626204287211635\n",
      "\n",
      "STEP 9\n",
      "----------\n",
      "Eigen Value = 10.3710\n",
      "Eigen Vector: \n",
      "1.000\t\n",
      "0.799\t\n",
      "0.698\t\n",
      "0.587\t\n",
      "0.906\t\n",
      "errror=0.0002929736523977766\n",
      "\n",
      "STEP 10\n",
      "----------\n",
      "Eigen Value = 10.3710\n",
      "Eigen Vector: \n",
      "1.000\t\n",
      "0.799\t\n",
      "0.698\t\n",
      "0.587\t\n",
      "0.906\t\n",
      "errror=1.366970549199209e-05\n",
      "\n",
      "STEP 11\n",
      "----------\n",
      "Eigen Value = 10.3710\n",
      "Eigen Vector: \n",
      "1.000\t\n",
      "0.799\t\n",
      "0.698\t\n",
      "0.587\t\n",
      "0.906\t\n",
      "errror=1.1045626154171373e-05\n",
      "\n",
      "STEP 12\n",
      "----------\n",
      "Eigen Value = 10.3710\n",
      "Eigen Vector: \n",
      "1.000\t\n",
      "0.799\t\n",
      "0.698\t\n",
      "0.587\t\n",
      "0.906\t\n",
      "errror=2.9280063689185454e-06\n",
      "\n",
      "STEP 13\n",
      "----------\n",
      "Eigen Value = 10.3710\n",
      "Eigen Vector: \n",
      "1.000\t\n",
      "0.799\t\n",
      "0.698\t\n",
      "0.587\t\n",
      "0.906\t\n",
      "errror=2.532766227858474e-07\n"
     ]
    }
   ],
   "source": [
    "# Power Method to Find Largest Eigen Value and Eigen Vector\n",
    "# Importing NumPy Library\n",
    "# https://www.codesansar.com/numerical-methods/power-method-largest-eigen-value-vector-python-program.htm\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\"\"\"\n",
    "# Reading order of matrix\n",
    "n = int(input('Enter order of matrix: '))\n",
    "\n",
    "# Making numpy array of n x n size and initializing \n",
    "# to zero for storing matrix\n",
    "a = np.zeros((n,n))\n",
    "\n",
    "# Reading matrix\n",
    "print('Enter Matrix Coefficients:')\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        a[i][j] = float(input( 'a['+str(i)+']['+ str(j)+']='))\n",
    "\"\"\"\n",
    "\n",
    "a = matrix\n",
    "\n",
    "# Making numpy array n x 1 size and initializing to zero\n",
    "# for storing initial guess vector\n",
    "n = a.shape[0]\n",
    "\n",
    "x = np.zeros((n))\n",
    "\n",
    "# Reading initial guess vector\n",
    "print('Enter initial guess vector: ')\n",
    "for i in range(n):\n",
    "    x[i] = float(input( 'x['+str(i)+']='))\n",
    "\n",
    "# Reading tolerable error\n",
    "tolerable_error = float(input('Enter tolerable error: '))\n",
    "\n",
    "# Reading maximum number of steps\n",
    "max_iteration = int(input('Enter maximum number of steps: '))\n",
    "\n",
    "# Power Method Implementation\n",
    "lambda_old = 1.0\n",
    "condition =  True\n",
    "step = 1\n",
    "while condition:\n",
    "    # Multiplying a and x\n",
    "    x = np.matmul(a,x)\n",
    "    \n",
    "    # Finding new Eigen value and Eigen vector\n",
    "    lambda_new = max(abs(x))\n",
    "    \n",
    "    x = x/lambda_new\n",
    "    \n",
    "    # Displaying Eigen value and Eigen Vector\n",
    "    print('\\nSTEP %d' %(step))\n",
    "    print('----------')\n",
    "    print('Eigen Value = %0.4f' %(lambda_new))\n",
    "    print('Eigen Vector: ')\n",
    "    for i in range(n):\n",
    "        print('%0.3f\\t' % (x[i]))\n",
    "    \n",
    "    # Checking maximum iteration\n",
    "    step = step + 1\n",
    "    if step > max_iteration:\n",
    "        print('Not convergent in given maximum iteration!')\n",
    "        break\n",
    "    \n",
    "    # Calculating error\n",
    "    error = abs(lambda_new - lambda_old)\n",
    "    print('errror='+ str(error))\n",
    "    lambda_old = lambda_new\n",
    "    condition = error > tolerable_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод  \n",
    "Таким образом мы получили алгоритм позволяющий находить наибольшее СЗ и соответствующий ему СВ.  \n",
    "Результат был проверен хорошо протестированной функцией в NumPy, а также через решенные задачи на mathprofi."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
